{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input , LSTM , Lambda , RepeatVector , TimeDistributed , Layer , Embedding , Dense\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "t4tnl1cz7gfG"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentences = [\n",
        "    \"AI is transforming the world.\",\n",
        "    \"DL model requires large data sets.\",\n",
        "    \"NLP enables chatbots.\",\n",
        "    \"Computer vision helps in image recommendation.\",\n",
        "    \"Generative models create realistic content.\",\n",
        "    \"Machine learning powers recommendation engines.\",\n",
        "    \"AI is revolutionizing healthcare diagnostics.\",\n",
        "    \"Deep learning mimics human brain functions.\",\n",
        "    \"Natural language processing boosts search accuracy.\",\n",
        "    \"Reinforcement learning optimizes robotic movement.\",\n",
        "    \"Supervised learning requires labeled data.\",\n",
        "    \"Unsupervised models discover hidden patterns.\",\n",
        "    \"Neural networks are inspired by the human brain.\",\n",
        "    \"AI improves customer service through automation.\",\n",
        "    \"Transfer learning speeds up model training.\",\n",
        "    \"CNNs are used in image classification.\",\n",
        "    \"RNNs are ideal for sequential data.\",\n",
        "    \"Transformers are the backbone of modern NLP.\",\n",
        "    \"GANs generate realistic fake images.\",\n",
        "    \"AI assists in medical image diagnosis.\",\n",
        "    \"ML algorithms detect fraud in transactions.\",\n",
        "    \"AI is used in autonomous vehicle systems.\",\n",
        "    \"Speech recognition converts voice to text.\",\n",
        "    \"NLP enables sentiment analysis on reviews.\",\n",
        "    \"AI chatbots handle customer queries efficiently.\",\n",
        "    \"AI-based systems enhance supply chain efficiency.\",\n",
        "    \"Computer vision helps in quality control.\",\n",
        "    \"AI detects anomalies in manufacturing.\",\n",
        "    \"Predictive analytics forecasts future trends.\",\n",
        "    \"Big data fuels machine learning models.\",\n",
        "    \"AI models classify email as spam or not.\",\n",
        "    \"Self-driving cars rely on deep learning.\",\n",
        "    \"AI models predict stock market trends.\",\n",
        "    \"AI in agriculture detects crop diseases.\",\n",
        "    \"Edge AI enables on-device predictions.\",\n",
        "    \"AI improves personalization in e-commerce.\",\n",
        "    \"AI tools enhance cybersecurity defenses.\",\n",
        "    \"AI helps detect deepfakes in media.\",\n",
        "    \"AI is applied in facial recognition systems.\",\n",
        "    \"AI models track user behavior online.\",\n",
        "    \"AI translates text between languages.\",\n",
        "    \"AI in finance helps assess credit risk.\",\n",
        "    \"AI systems generate music and art.\",\n",
        "    \"AI helps automate repetitive tasks.\",\n",
        "    \"ML helps in churn prediction for companies.\",\n",
        "    \"Reinforcement learning trains game agents.\",\n",
        "    \"AI in logistics optimizes delivery routes.\",\n",
        "    \"AI is transforming the legal industry.\",\n",
        "    \"AI helps in drug discovery research.\",\n",
        "    \"Robotics combined with AI improves manufacturing.\",\n",
        "    \"ML models help in market segmentation.\",\n",
        "    \"AI detects network intrusions.\",\n",
        "    \"AI systems recommend movies and shows.\",\n",
        "    \"AI chatbots simulate human conversation.\",\n",
        "    \"Voice assistants use NLP for commands.\",\n",
        "    \"AI enables hands-free smart devices.\",\n",
        "    \"Image recognition identifies objects and faces.\",\n",
        "    \"AI personalizes online learning experiences.\",\n",
        "    \"AI powers virtual teaching assistants.\",\n",
        "    \"ML improves energy usage predictions.\",\n",
        "    \"AI in retail optimizes inventory management.\",\n",
        "    \"AI is reshaping the entertainment industry.\",\n",
        "    \"AI algorithms detect product defects.\",\n",
        "    \"AI improves quality control in factories.\",\n",
        "    \"AI accelerates data labeling processes.\",\n",
        "    \"AI helps in climate modeling and forecasting.\",\n",
        "    \"ML in insurance assesses claim risks.\",\n",
        "    \"AI enhances fraud detection mechanisms.\",\n",
        "    \"AI reads and summarizes long documents.\",\n",
        "    \"AI helps generate synthetic data.\",\n",
        "    \"ML models predict customer lifetime value.\",\n",
        "    \"AI is used in smart home automation.\",\n",
        "    \"AI supports emotion detection from images.\",\n",
        "    \"AI helps in content moderation on social platforms.\",\n",
        "    \"AI systems understand natural language queries.\",\n",
        "    \"AI enables smart search recommendations.\",\n",
        "    \"ML improves dynamic pricing strategies.\",\n",
        "    \"AI predicts customer purchasing behavior.\",\n",
        "    \"AI enhances AR and VR experiences.\",\n",
        "    \"AI supports real-time translation services.\",\n",
        "    \"AI identifies trends from social media.\",\n",
        "    \"AI is used in handwriting recognition.\",\n",
        "    \"AI assists with document classification.\",\n",
        "    \"ML aids in target marketing campaigns.\",\n",
        "    \"AI helps automate resume screening.\",\n",
        "    \"AI bots aid in virtual interviews.\",\n",
        "    \"AI supports accessibility tools for the disabled.\",\n",
        "    \"AI monitors worker safety in industries.\",\n",
        "    \"ML models detect disease outbreaks early.\",\n",
        "    \"AI powers interactive learning apps.\",\n",
        "    \"AI improves video surveillance analytics.\",\n",
        "    \"AI helps optimize ad placement strategies.\",\n",
        "    \"ML is used in predictive text typing.\",\n",
        "    \"AI assists in drone navigation systems.\",\n",
        "    \"AI enables emotion-aware applications.\",\n",
        "    \"ML helps optimize sales forecasts.\",\n",
        "    \"AI drives intelligent automation tools.\",\n",
        "    \"AI speeds up document verification.\",\n",
        "    \"AI helps with smart farming practices.\",\n",
        "    \"ML improves personalized product recommendations.\",\n",
        "    \"AI tools power automated translation.\",\n",
        "    \"AI enhances call center efficiency.\",\n",
        "    \"AI provides insights from large datasets.\",\n",
        "    \"AI is reshaping how businesses operate.\",\n",
        "    \"ML helps predict housing prices.\",\n",
        "    \"AI systems automate\",\n",
        "]"
      ],
      "metadata": {
        "id": "5e98YceP7lwD"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Sequence\n",
        "#Tokenizer\n",
        "vocab_list = 100\n",
        "Sequence_length = 10\n",
        "text_processor = Tokenizer(num_words=vocab_list, oov_token=\"<OOV>\")\n",
        "text_processor.fit_on_texts(sample_sentences)\n",
        "tokenized = text_processor.texts_to_sequences(sample_sentences)\n",
        "padded_sequences = pad_sequences(tokenized, maxlen=Sequence_length, padding=\"post\")"
      ],
      "metadata": {
        "id": "ejfY1SHm8bgF"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Config\n",
        "embed_dim = 64\n",
        "latent_space = 16"
      ],
      "metadata": {
        "id": "hyvTrWwp9E22"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoder\n",
        "input_layer = Input(shape=(Sequence_length,),name=\"text_input\")\n",
        "embed_layer = Embedding(input_dim=vocab_list, output_dim=embed_dim,mask_zero=True)(input_layer)\n",
        "lstm_encoded = LSTM(64)(embed_layer)"
      ],
      "metadata": {
        "id": "wVPINloc9P66"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_mu = Dense(latent_space, name=\"latent_mean\")(lstm_encoded)\n",
        "z_log_sigma = Dense(latent_space, name=\"latent_log_var\")(lstm_encoded)"
      ],
      "metadata": {
        "id": "Gdx998yn-P_C"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_data(args):\n",
        "    mu, log_sigma = args\n",
        "    eps = K.random_normal(shape=K.shape(mu))\n",
        "    return mu + K.exp(log_sigma) * eps"
      ],
      "metadata": {
        "id": "ZcFquqiH-skr"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z_vector = Lambda(sample_data , name='latent_sampler')([z_mu,z_log_sigma])"
      ],
      "metadata": {
        "id": "1NU0QLDq_RiX"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KL Divergence as Layer\n",
        "class KLLoss(Layer):\n",
        "  def call (self,inputs):\n",
        "    mu, log_sigma = inputs\n",
        "    kl = -0.5 * K.sum(1 + log_sigma - K.square(mu) - K.exp(log_sigma),axis=1)\n",
        "    self.add_loss(K.mean(kl))\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "yaRG-DVC_maF"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Kl_triggers =KLLoss()([z_mu,z_log_sigma]) #Activation Kl loss"
      ],
      "metadata": {
        "id": "kJJn0WuiANcp"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoder\n",
        "repeat_z = RepeatVector(Sequence_length)(Z_vector)\n",
        "decoded_lstm = LSTM(64,return_sequences=True)(repeat_z)\n",
        "decoded_output = TimeDistributed(Dense(vocab_list,activation='softmax'))(decoded_lstm)"
      ],
      "metadata": {
        "id": "bg6DtTb7CjUV"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Full VAE Model\n",
        "vae_model = Model(input_layer,decoded_output,name=\"text_vae_model\")\n",
        "vae_model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\")"
      ],
      "metadata": {
        "id": "0030cDqADK9d"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare output for training\n",
        "target_output = np.expand_dims(padded_sequences,-1)\n",
        "vae_model.fit(padded_sequences,target_output,epochs=50,batch_size=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZq2gFgvDoWf",
        "outputId": "e6ce6816-971e-479b-91f2-b38026b8e4f0"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 4.4508\n",
            "Epoch 2/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.4932\n",
            "Epoch 3/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.1204\n",
            "Epoch 4/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2.0449\n",
            "Epoch 5/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.9723\n",
            "Epoch 6/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.6908\n",
            "Epoch 7/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.7582\n",
            "Epoch 8/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.6709\n",
            "Epoch 9/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.6417\n",
            "Epoch 10/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.6666\n",
            "Epoch 11/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.6978\n",
            "Epoch 12/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.5743\n",
            "Epoch 13/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6127\n",
            "Epoch 14/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.6184\n",
            "Epoch 15/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.5780\n",
            "Epoch 16/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.5531\n",
            "Epoch 17/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5291\n",
            "Epoch 18/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4349\n",
            "Epoch 19/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.5598\n",
            "Epoch 20/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.4099\n",
            "Epoch 21/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 1.5343\n",
            "Epoch 22/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.4292\n",
            "Epoch 23/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.4931\n",
            "Epoch 24/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4274\n",
            "Epoch 25/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.4038\n",
            "Epoch 26/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3461\n",
            "Epoch 27/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.3765\n",
            "Epoch 28/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4473\n",
            "Epoch 29/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3992\n",
            "Epoch 30/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2801\n",
            "Epoch 31/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.3368\n",
            "Epoch 32/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.2400\n",
            "Epoch 33/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.2222\n",
            "Epoch 34/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.2969\n",
            "Epoch 35/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.2673\n",
            "Epoch 36/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.2380\n",
            "Epoch 37/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.1734\n",
            "Epoch 38/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.1702\n",
            "Epoch 39/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.1665\n",
            "Epoch 40/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.1433\n",
            "Epoch 41/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.1802\n",
            "Epoch 42/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.1390\n",
            "Epoch 43/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.1233\n",
            "Epoch 44/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.0643\n",
            "Epoch 45/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.0572\n",
            "Epoch 46/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.0237\n",
            "Epoch 47/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0268\n",
            "Epoch 48/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.9459\n",
            "Epoch 49/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0485\n",
            "Epoch 50/50\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0204\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d07eac98d50>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder model\n",
        "text_encoder = Model(input_layer,z_mu,name=\"text_encoder\")"
      ],
      "metadata": {
        "id": "MTC2opl5EA4N"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(target_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9u9x73ZnK7Y",
        "outputId": "afb55510-d056-4a53-f662-07a9d7bde405"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 2]\n",
            "  [ 6]\n",
            "  [42]\n",
            "  ...\n",
            "  [ 0]\n",
            "  [ 0]\n",
            "  [ 0]]\n",
            "\n",
            " [[95]\n",
            "  [43]\n",
            "  [44]\n",
            "  ...\n",
            "  [ 0]\n",
            "  [ 0]\n",
            "  [ 0]]\n",
            "\n",
            " [[16]\n",
            "  [13]\n",
            "  [26]\n",
            "  ...\n",
            "  [ 0]\n",
            "  [ 0]\n",
            "  [ 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 2]\n",
            "  [ 6]\n",
            "  [84]\n",
            "  ...\n",
            "  [ 0]\n",
            "  [ 0]\n",
            "  [ 0]]\n",
            "\n",
            " [[ 5]\n",
            "  [ 4]\n",
            "  [36]\n",
            "  ...\n",
            "  [ 0]\n",
            "  [ 0]\n",
            "  [ 0]]\n",
            "\n",
            " [[ 2]\n",
            "  [10]\n",
            "  [37]\n",
            "  ...\n",
            "  [ 0]\n",
            "  [ 0]\n",
            "  [ 0]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sYhvYJvnrBL",
        "outputId": "23988f94-eae1-488e-b696-9a056345ba58"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Functional name=text_encoder, built=True>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoder Model\n",
        "latent_input = Input(shape=(latent_space,) , name=\"decoder_input\")\n",
        "repeated_input = RepeatVector(Sequence_length)(latent_input)\n",
        "decoder_seq = LSTM(64,return_sequences=True)(repeated_input)\n",
        "final_output = TimeDistributed(Dense(vocab_list,activation='softmax'))(decoder_seq)\n",
        "text_decoder = Model(latent_input,final_output,name=\"decoder_only\")"
      ],
      "metadata": {
        "id": "_MWNtt4hnsbA"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "random_z = np.random.normal(size=(1,latent_space))\n",
        "generated_sequence_probs = text_decoder.predict(random_z)\n",
        "generated_sequence_ids = np.argmax(generated_sequence_probs,axis=-1)[0]\n",
        "index_to_word = {v: k for k , v in text_processor.word_index.items()}\n",
        "index_to_word[0] = ' '\n",
        "index_to_word[text_processor.word_index.get('<OOV>')] = '<OOV>'\n",
        "generated_words = [index_to_word.get(idx,\"<UNK>\") for idx in generated_sequence_ids]\n",
        "generated_text = ' '.join(generated_words).strip()\n",
        "print(\"Generated Text :\\n\",generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmA6ub5euC3_",
        "outputId": "ca7a7146-6e8c-4823-9526-1eb1df16effe"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step\n",
            "Generated Text :\n",
            " detection detection detection learning learning learning learning learning learning learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def temp_sampling(probability,temp = 1.0):\n",
        "    a = np.log(probability+1e-9)/temp\n",
        "    b = np.exp(a)\n",
        "    c = b/np.sum(b)\n",
        "    return np.random.choice(len(c),p=c)\n",
        "\n",
        "temp = 0.5\n",
        "random_z = np.random.normal(size=(1,latent_space))\n",
        "generated_sequence_probs = text_decoder.predict(random_z)[0]\n",
        "generated_sequence_ids = [temp_sampling(words,temp) for words in generated_sequence_probs]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kAFIsrFuSuM",
        "outputId": "c48aca4e-49ad-433f-a6bd-e2bd77f6ca54"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert idx to words\n",
        "index_to_word = text_processor.index_word\n",
        "index_to_word[0] = \" \"\n",
        "generated_words = [index_to_word.get(idx,\"<UNK>\") for idx in generated_sequence_ids]\n",
        "generated_text = ' '.join(generated_words).strip()\n",
        "print(\"Generated Text :\\n\",generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H5bKugZ27gK",
        "outputId": "aacd04ec-eb18-4cc6-f67f-8ce9fffb7eca"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text :\n",
            " in from enables on fraud improves queries large from is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Image generator\n",
        "#Encoder\n",
        "#Decoder\n",
        "#loss\n",
        "#NLP"
      ],
      "metadata": {
        "id": "2puT9OAC-yyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Questions\n",
        "#1. What is Tokenizer\n",
        "#2. What is Embedding\n",
        "#3. What is Stop word\n",
        "#4. NLU\n",
        "#5. NLZ\n",
        "#6. What is bag of words\n",
        "#7. What is stemming\n",
        "#8. What is IDF\n",
        "#9. What is POS tagging\n",
        "#10. Explain Embedding Techniques\n",
        "#11. Count Vectorizer\n",
        "#12. diff between count and tfidf vectorizer\n",
        "#13. what is Transformer and how it works '\n",
        "#14. what is VERT model\n",
        "#15. How Woulld you handle out of vocabulary words in text corpus\n",
        "#16. What is masked language model (MLM)\n",
        "#17. what is NMT (Neural machine translator)\n",
        "#18. Pre-trained NMT model : helsiki-opus-mt-x-yy , Facebook/WMT-19-en-de , T5-base/T5-Large , Facebook/MLLB-200-distilled-600M\n"
      ],
      "metadata": {
        "id": "TlNa-og_Ax8e"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r60Hgc90B5w5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}